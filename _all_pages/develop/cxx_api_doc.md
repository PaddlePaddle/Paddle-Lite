# CreatePaddlePredictor

```c++
template <typename ConfigT>
std::shared_ptr<PaddlePredictor> CreatePaddlePredictor(const ConfigT&);
```

`CreatePaddlePredictor`??¨æ????¹æ??`MobileConfig`????»ºé¢??????¨ã??

ç¤ºä??ï¼??
```c++
// è®¾ç½®MobileConfig
MobileConfig config;
config.set_model_dir(FLAGS_model_dir);

// ??¹æ??MobileConfig????»ºPaddlePredictor
std::shared_ptr<PaddlePredictor> predictor = CreatePaddlePredictor<MobileConfig>(config);
```

??????ï¼??
- `config(MobileConfig)` - ??¨ä??????»ºPredictor??????ç½®ä¿¡??¯ã??

è¿????ï¼??PaddlePredictor`??????

è¿????ç±»å??ï¼??std::shared_ptr<PaddlePredictor>`

# MobileConfig

```c++
class MobileConfig
```

`MobileConfig`??¨æ??????½®????»ºè½»é??çº??addlePredictor??????ç½®ä¿¡??¯ï??å¦??aiveBuffer??¼å??????¨¡????????????æ¨¡å????????å­????????ä»????å­????è½½æ¨¡??????ä½¿ç??)??????????¨¡å¼????å·¥ä??çº¿ç????°ç??ç­????

*æ³¨æ??ï¼??????¥ç??æ¨¡å????????ä½¿ç??Model Optimize Toolè½¬å??ä¸??aiveBuffer??¼å????????????¨¡??????*

ç¤ºä??ï¼??
```c++
MobileConfig config;
// è®¾ç½®NaiveBuffer??¼å??æ¨¡å????®å??ï¼????????»¶????½½æ¨¡å????¶ä½¿????config.set_model_dir(FLAGS_model_dir);
// è®¾ç½®å·¥ä??çº¿ç??????config.set_threads(4);
// è®¾ç½®??½è??æ¨¡å??
config.set_power_mode(LITE_POWER_HIGH);

// ??¹æ??MobileConfig????»ºPaddlePredictor
std::shared_ptr<PaddlePredictor> predictor = CreatePaddlePredictor<MobileConfig>(config);
```

> **set_model_dir(model_dir)**

è®¾ç½®æ¨¡å??????»¶å¤¹è·¯å¾????å½????è¦????ç£????????½½æ¨¡å????¶ä½¿??¨ã??

??????ï¼??
- `model_dir(std::string)` - æ¨¡å??????»¶å¤¹è·¯å¾??
è¿????ï¼??None`

è¿????ç±»å??ï¼??void`



> **model_dir()**

è¿????è®¾ç½®????¨¡??????ä»¶å¤¹è·¯å??????
??????ï¼??
- `None`

è¿????ï¼??¨¡??????ä»¶å¤¹è·¯å??

è¿????ç±»å??ï¼??std::string`



> **set_model_buffer(model_buffer, model_buffer_size, param_buffer, param_buffer_size)**

è®¾ç½®æ¨¡å??????????°ç??????????°å??ï¼??????????ä»????å­????è½½æ¨¡??????ä½¿ç??????
ç¤ºä??ï¼??
```c++
// è¯»å??æ¨¡å??????»¶??°å??å­??std::string model_buffer = ReadFile(FLAGS_model_path);
std::string params_buffer = lite::ReadFile(FLAGS_params_path);

// è®¾ç½®MobileConfig
lite_api::MobileConfig config;
config.set_model_buffer(model_buffer.c_str(), model_buffer.size(), 
                                params_buffer.c_str(), params_buffer.size());

// ??¹æ??MobileConfig????»ºPaddlePredictor
std::shared_ptr<PaddlePredictor> predictor = CreatePaddlePredictor<MobileConfig>(config);
```

??????ï¼??
- `model_buffer(const char*)` - ??????ä¸­æ¨¡??????????????®ã??
- `model_buffer_size(size_t)` - ??????ä¸­æ¨¡??????????????®ç??å¤§å??????- `param_buffer(const char*)` - ??????ä¸­æ¨¡????????°æ????®ã??
- `param_buffer_size(size_t)` - ??????ä¸­æ¨¡????????°æ????®ç??å¤§å??????
è¿????ï¼??None`

è¿????ç±»å??ï¼??Void`



> **model_from_memory()**

??¯å??ä»????å­??¸­????½½æ¨¡å??ï¼????ä½¿ç??`set_model_buffer`??¥å????¶è??????true`

??????ï¼??
- `None`

è¿????ï¼????????????????????½½æ¨¡å??

è¿????ç±»å??ï¼??bool`



> **model_buffer()**

??·å????????ä¸­æ¨¡??????????????®ã??

??????ï¼??
- `None`

è¿????ï¼????å­??¸­æ¨¡å??ç»??????°æ??

è¿????ç±»å??ï¼??const std::string&`



> **param_buffer()**

??·å????????ä¸­æ¨¡????????°æ????®ã??

??????ï¼??
- `None`

è¿????ï¼????å­??¸­æ¨¡å??ç»??????°æ??

è¿????ç±»å??ï¼??const std::string&`



> **set_power_mode(mode)**

è®¾ç½®CPU??½è??æ¨¡å??????
*æ³¨æ??ï¼??????¨å??????OpenMP`??¶ç??????????????ç³»ç????ªå??è°??º¦????

??????ï¼??
- `mode(PowerMode)` - CPU??½è??æ¨¡å????????è®¤ä¸º`LITE_POWER_HIGH`????
è¿????ï¼??None`

è¿????ç±»å??ï¼??void`



> **power_mode()**

??·å??è®¾ç½®????PU??½è??æ¨¡å??????
??????ï¼??
- `None`

è¿????ï¼??®¾ç½®ç??CPU??½è??æ¨¡å??

è¿????ç±»å??ï¼??PowerMode`



> **set_threads(threads)**

è®¾ç½®å·¥ä??çº¿ç????°ã??

*æ³¨æ??ï¼??????¨å??????OpenMP`????¨¡å¼??????????ï¼??????????ä½¿ç??????º¿ç¨????*

??????ï¼??
- `threads(int)` - å·¥ä??çº¿ç????°ã??é»??®¤ä¸??????
è¿????ï¼??None`

è¿????ç±»å??ï¼??void`



> **threads()**

??·å??è®¾ç½®????·¥ä½??º¿ç¨????????
??????ï¼??
- `None`

è¿????ï¼??·¥ä½??º¿ç¨????

è¿????ç±»å??ï¼??int`

# PaddlePredictor

```c++
class PaddlePredictor
```

`PaddlePredictor`????addle-Lite??????æµ????ï¼????`CreatePaddlePredictor`??¹æ??`MobileConfig`è¿????????»º????????·å??ä»¥æ??????addlePredictor??????????????£è®¾ç½®è????¥æ????®ã????§è??æ¨¡å??é¢??????????????????ºä»¥??????å¾????????½¿????ib????????¬ä¿¡??¯ç??????
ç¤ºä??ï¼??
```c++
int64_t ShapeProduction(const shape_t& shape) {
      int64_t res = 1;
        for (auto i : shape) res *= i;
          return res;
}

// è®¾ç½®MobileConfig
MobileConfig config;
config.set_model_dir(FLAGS_model_dir);

// ??¹æ??MobileConfig????»ºPaddlePredictor
std::shared_ptr<PaddlePredictor> predictor = CreatePaddlePredictor<MobileConfig>(config);

// ??????è¾??????°æ??
std::unique_ptr<Tensor> input_tensor(std::move(predictor->GetInput(0)));
input_tensor->Resize({1, 3, 224, 224});
auto* data = input_tensor->mutable_data<float>();
for (int i = 0; i < ShapeProduction(input_tensor->shape()); ++i) {
      data[i] = 1;
}

// ??§è??é¢????
predictor->Run();

// ??·å??è¾????
std::unique_ptr<const Tensor> output_tensor(std::move(predictor->GetOutput(0)));
printf("Output dim: %d\n", output_tensor->shape()[1]);
for (int i = 0; i < ShapeProduction(output_tensor->shape()); i += 100) {
      printf("Output[%d]: %f\n", i, output_tensor->data<float>()[i]);
}
```

> **GetInput(index)**

??·å??è¾????Tensor??????ï¼??????¥è®¾ç½®æ¨¡??????è¾??????°æ??????
??????ï¼??
- `index(int)` - è¾????Tensor????´¢å¼??
è¿????ï¼??¬¬`index`ä¸ªè??????Tensor`??????????
è¿????ç±»å??ï¼??std::unique_ptr<Tensor>`



> **GetOutput(index)**

??·å??è¾????Tensor??????????????¨æ????·å??æ¨¡å??????????ºç????????

??????ï¼??
- `index(int)` - è¾“????ensor????´¢å¼??
è¿????ï¼??¬¬`index`ä¸ªè??????ensor`??????????
è¿????ç±»å??ï¼??std::unique_ptr<Tensor>`



> **Run()**

??§è¡??¨¡??????æµ??????????????**è®¾ç½®è¾??????°æ??????**è°??????‚
??????ï¼??
- `None`

è¿????ï¼??None`

è¿????ç±»å??ï¼??void`



> **GetVersion()**

??¨ä????·å??å½????libä½¿ç??????»£????????¬ã????¥ä»£????????¸å??tag??????????agä¿¡æ??ï¼????`v2.0-beta`ï¼›??????è¿????ä»£ç??????branch(commitid)`ï¼????`develop(7e44619)`????
??????ï¼??
- `None`

è¿????ï¼????????ibä½¿ç??????»£??????æ??ä¿¡æ??

è¿????ç±»å??ï¼??std::string`

# PowerMode

```c++
enum PowerMode;
```

`PowerMode`ä¸??RM CPU??½è??æ¨¡å??ï¼??????·å??ä»¥æ????®å????¨å????¯è®¾ç½®è??????¨¡å¼????å¾????ä¼??????½æ??æ¯”????
ç¤ºä??ï¼??
```c++
MobileConfig config;
// è®¾ç½®NaiveBuffer??¼å??æ¨¡å????®å??
config.set_model_dir(FLAGS_model_dir);
// è®¾ç½®è??????¨¡å¼??config.set_power_mode(LITE_POWER_HIGH);

// æ??????obileConfig????»ºPaddlePredictor
std::shared_ptr<PaddlePredictor> predictor = CreatePaddlePredictor<MobileConfig>(config);
```

PowerModeè¯????è¯´æ??å¦????ï¼??
|         ????¡¹         | è¯´æ??                                                         |
| :------------------: | ------------------------------------------------------------ |
|   LITE_POWER_HIGH    | ç»????å¤§??¸è??è¡??¨¡å¼????å¦????ARM CPU??¯æ??big.LITTLEï¼????ä¼????ä½¿ç??å¹¶ç??å®??ig cluster??????????®¾ç½®ç??çº¿ç????°å¤§äº??¤§??¸??°é??ï¼????ä¼????çº¿ç????°è????¨ç¼©??¾å??å¤§æ????°é??????????œç³»ç??ä¸??????¨å¤§??¸æ????????ä¸??????????????????µé????????ä¸‹ä¼??????°ç????¸å¤±è´¥ï??å¦????å¤±è´¥????????¥ä??ç»????æ¨¡å????‚ |
|    LITE_POWER_LOW    | ç»????å°????è¿????æ¨¡å????????????RM CPU??¯æ??big.LITTLEï¼????ä¼????ä½¿ç??å¹¶ç??å®??ittle clusterã??å¦????è®¾ç½®????º¿ç¨????å¤§ä??å°??????°é??ï¼????ä¼????çº¿ç??æ????ªå??ç¼©æ????°å????¸æ????????å¦??????¾ä????°å????¸ï????????å??è¿????ä¸??????¸æ¨¡å¼???? |
|   LITE_POWER_FULL    | å¤§å????¸æ··ç??æ¨¡å??????º¿ç¨??????¯ä»¥å¤§ä??å¤§æ????°é????????çº¿ç????°å¤§ä????¸å????°é????¶ï??????????ªå??å°??º¿ç¨????ç¼©æ????°æ??å¿ƒ??°é??????|
|  LITE_POWER_NO_BIND  | ä¸??????¸è??è¡??¨¡å¼??????¨è??ï¼????ç³»ç????¹æ??è´??½½??ªå??è°??º¦ä»»å????°ç©º??²ç??CPU??¸å??ä¸???? |
| LITE_POWER_RAND_HIGH | è½®æ??ç»????å¤§æ??æ¨¡å??ã??å¦????Big cluster??????ä¸ªæ??å¿??????????é¢????10æ¬¡å????????ç»??????°ä??ä¸??¸ª??¸å??????|
| LITE_POWER_RAND_LOW  | è½®æ??ç»????å°????æ¨¡å????????????ittle cluster??????ä¸ªæ??å¿??????????é¢????10æ¬¡å????????ç»??????°ä??ä¸??¸ª??¸å??????|



# Tensor

```c++
class Tensor
```

Tensor????addle-Lite????????®ç??ç»??½¢å¼??????¨ä??å¯¹å??å±??????®è??è¡????£??¹¶????????¥å??å¯¹æ????®è¿??????????ï¼??????¬è®¾ç½??hape????????®ã??LoDä¿¡æ??ç­????

*æ³¨????????¨æ??åº??½¿????PaddlePredictor`????GetInput`????GetOuput`??¥å????·å??è¾????/è¾????????Tensor`????

ç¤ºä??ï¼??
```c++
int64_t ShapeProduction(const shape_t& shape) {
      int64_t res = 1;
        for (auto i : shape) res *= i;
          return res;
}

// è®¾ç½®MobileConfig
MobileConfig config;
config.set_model_dir(FLAGS_model_dir);

// ??¹æ??MobileConfig????»ºPaddlePredictor
std::shared_ptr<PaddlePredictor> predictor = CreatePaddlePredictor<MobileConfig>(config);

// ??????è¾??????°æ??, ??·å??è¾????Tensor
std::unique_ptr<Tensor> input_tensor(std::move(predictor->GetInput(0)));
// è®¾ç½®è¾????Tensorç»´åº¦ä¿¡æ??
input_tensor->Resize({1, 3, 224, 224});
// è®¾ç½®è¾??????°æ??
auto* data = input_tensor->mutable_data<float>();
for (int i = 0; i < ShapeProduction(input_tensor->shape()); ++i) {
      data[i] = 1;
}

// ??§è??é¢????
predictor->Run();

// ??·å??è¾????Tensor
std::unique_ptr<const Tensor> output_tensor(std::move(predictor->GetOutput(0)));
// ??·å??è¾????Tensorç»´åº¦
printf("Output dim: %d\n", output_tensor->shape()[1]);
// ??·å??è¾????Tensor??°æ??
for (int i = 0; i < ShapeProduction(output_tensor->shape()); i += 100) {
      printf("Output[%d]: %f\n", i, output_tensor->data<float>()[i]);
}
```

> **Resize(shape)**

è®¾ç½®Tensor????»´åº??¿¡??¯ã??

??????ï¼??
- `shape(std::vector<int64_t>)` - ç»´åº¦ä¿¡æ??

è¿????ï¼??None`

è¿????ç±»å??ï¼??void`



> **shape()**

??·å??Tensor????»´åº??¿¡??¯ã??

??????ï¼??
- `None`

è¿????ï¼??ensor????»´åº??¿¡æ??

è¿????ç±»å??ï¼??std::vector<int64_t>`



> **data<T>()**

```c++
template <typename T>
const T* data() const;
```

??·å??ensor??????å±??????®ç??å¸¸é????????ï¼??????®ä????¥ç??ä¸????æ¨¡å??ç±»å????·å????¸å????°æ????????äº??¯»????ensor??°æ??????
ç¤ºä¾????

```c++
std::unique_ptr<const Tensor> output_tensor(std::move(predictor->GetOutput(0)));
// å¦????æ¨¡å??ä¸­è????ºä¸ºfloatç±»å??
output_tensor->data<float>()
    ```

    ??????ï¼??
    - `None`

    è¿????ï¼??Tensor`åº??????°æ??å¸¸é????????

    è¿????ç±»å??ï¼??const T*`



    > **mutable_data<T>()**

    ```c++
    template <typename T>
    T* mutable_data() const;
    ```

    ??·å??Tensor??????å±??????®ç????????ï¼??????®ä????¥ç??ä¸????æ¨¡å??ç±»å????·å????¸å????°æ??????”¨ä??è®¾ç½®Tensor??°æ??????
    ç¤ºä??ï¼??
    ```c++
    std::unique_ptr<Tensor> input_tensor(std::move(predictor->GetInput(0)));
    // å¦????¨¡????¸­è¾????ä¸??loatç±»å??
    auto* data = input_tensor->mutable_data<float>();
    // è®¾ç½®Tensor??°æ??
    for (int i = 0; i < ShapeProduction(input_tensor->shape()); ++i) {
          data[i] = 1;
    }
```

??????ï¼??
- `None`

è¿????ï¼??Tensor`åº??????°æ????????

è¿????ç±»å??ï¼??T*`



> **SetLoD(lod)**

è®¾ç½®Tensor????oDä¿¡æ¯ã??

??????ï¼??
- `lod(std::vector<std::vector<uint64_t>>)` - Tensor????oDä¿¡æ??

è¿????ï¼??None`

è¿????ç±»å??ï¼??void`



> **lod()**

??·å??Tensor????oDä¿¡æ??

??????ï¼??
- `None`

è¿????ï¼??Tensor`????oDä¿¡æ??

è¿????ç±»å??ï¼??std::vector<std::vector<uint64_t>>`
