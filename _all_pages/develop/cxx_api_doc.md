# CreatePaddlePredictor

```c++
template <typename ConfigT>
std::shared_ptr<PaddlePredictor> CreatePaddlePredictor(const ConfigT&);
```

`CreatePaddlePredictor`??®Ê????πÊ??`MobileConfig`????ª∫È¢??????®„??

Á§∫‰??Ôº??
```c++
// ËÆæÁΩÆMobileConfig
MobileConfig config;
config.set_model_dir(FLAGS_model_dir);

// ??πÊ??MobileConfig????ª∫PaddlePredictor
std::shared_ptr<PaddlePredictor> predictor = CreatePaddlePredictor<MobileConfig>(config);
```

??????Ôº??
- `config(MobileConfig)` - ??®‰??????ª∫Predictor??????ÁΩÆ‰ø°??Ø„??

Ëø????Ôº??PaddlePredictor`??????

Ëø????Á±ªÂ??Ôº??std::shared_ptr<PaddlePredictor>`

# MobileConfig

```c++
class MobileConfig
```

`MobileConfig`??®Ê??????ΩÆ????ª∫ËΩªÈ??Á∫??addlePredictor??????ÁΩÆ‰ø°??ØÔ??Â¶??aiveBuffer??ºÂ??????®°????????????Ê®°Â????????Â≠????????‰ª????Â≠????ËΩΩÊ®°??????‰ΩøÁ??)??????????®°Âº????Â∑•‰??Á∫øÁ????∞Á??Á≠????

*Ê≥®Ê??Ôº??????•Á??Ê®°Â????????‰ΩøÁ??Model Optimize ToolËΩ¨Â??‰∏??aiveBuffer??ºÂ????????????®°??????*

Á§∫‰??Ôº??
```c++
MobileConfig config;
// ËÆæÁΩÆNaiveBuffer??ºÂ??Ê®°Â????ÆÂ??Ôº????????ª∂????ΩΩÊ®°Â????∂‰Ωø????config.set_model_dir(FLAGS_model_dir);
// ËÆæÁΩÆÂ∑•‰??Á∫øÁ??????config.set_threads(4);
// ËÆæÁΩÆ??ΩË??Ê®°Â??
config.set_power_mode(LITE_POWER_HIGH);

// ??πÊ??MobileConfig????ª∫PaddlePredictor
std::shared_ptr<PaddlePredictor> predictor = CreatePaddlePredictor<MobileConfig>(config);
```

> **set_model_dir(model_dir)**

ËÆæÁΩÆÊ®°Â??????ª∂Â§πË∑ØÂæ????ÂΩ????Ë¶????Á£????????ΩΩÊ®°Â????∂‰Ωø??®„??

??????Ôº??
- `model_dir(std::string)` - Ê®°Â??????ª∂Â§πË∑ØÂæ??
Ëø????Ôº??None`

Ëø????Á±ªÂ??Ôº??void`



> **model_dir()**

Ëø????ËÆæÁΩÆ????®°??????‰ª∂Â§πË∑ØÂ??????
??????Ôº??
- `None`

Ëø????Ôº??®°??????‰ª∂Â§πË∑ØÂ??

Ëø????Á±ªÂ??Ôº??std::string`



> **set_model_buffer(model_buffer, model_buffer_size, param_buffer, param_buffer_size)**

ËÆæÁΩÆÊ®°Â??????????∞Á??????????∞Â??Ôº??????????‰ª????Â≠????ËΩΩÊ®°??????‰ΩøÁ??????
Á§∫‰??Ôº??
```c++
// ËØªÂ??Ê®°Â??????ª∂??∞Â??Â≠??std::string model_buffer = ReadFile(FLAGS_model_path);
std::string params_buffer = lite::ReadFile(FLAGS_params_path);

// ËÆæÁΩÆMobileConfig
lite_api::MobileConfig config;
config.set_model_buffer(model_buffer.c_str(), model_buffer.size(), 
                                params_buffer.c_str(), params_buffer.size());

// ??πÊ??MobileConfig????ª∫PaddlePredictor
std::shared_ptr<PaddlePredictor> predictor = CreatePaddlePredictor<MobileConfig>(config);
```

??????Ôº??
- `model_buffer(const char*)` - ??????‰∏≠Ê®°??????????????Æ„??
- `model_buffer_size(size_t)` - ??????‰∏≠Ê®°??????????????ÆÁ??Â§ßÂ??????- `param_buffer(const char*)` - ??????‰∏≠Ê®°????????∞Ê????Æ„??
- `param_buffer_size(size_t)` - ??????‰∏≠Ê®°????????∞Ê????ÆÁ??Â§ßÂ??????
Ëø????Ôº??None`

Ëø????Á±ªÂ??Ôº??Void`



> **model_from_memory()**

??ØÂ??‰ª????Â≠??∏≠????ΩΩÊ®°Â??Ôº????‰ΩøÁ??`set_model_buffer`??•Â????∂Ë??????true`

??????Ôº??
- `None`

Ëø????Ôº????????????????????ΩΩÊ®°Â??

Ëø????Á±ªÂ??Ôº??bool`



> **model_buffer()**

??∑Â????????‰∏≠Ê®°??????????????Æ„??

??????Ôº??
- `None`

Ëø????Ôº????Â≠??∏≠Ê®°Â??Áª??????∞Ê??

Ëø????Á±ªÂ??Ôº??const std::string&`



> **param_buffer()**

??∑Â????????‰∏≠Ê®°????????∞Ê????Æ„??

??????Ôº??
- `None`

Ëø????Ôº????Â≠??∏≠Ê®°Â??Áª??????∞Ê??

Ëø????Á±ªÂ??Ôº??const std::string&`



> **set_power_mode(mode)**

ËÆæÁΩÆCPU??ΩË??Ê®°Â??????
*Ê≥®Ê??Ôº??????®Â??????OpenMP`??∂Á??????????????Á≥ªÁ????™Â??Ë∞??∫¶????

??????Ôº??
- `mode(PowerMode)` - CPU??ΩË??Ê®°Â????????ËÆ§‰∏∫`LITE_POWER_HIGH`????
Ëø????Ôº??None`

Ëø????Á±ªÂ??Ôº??void`



> **power_mode()**

??∑Â??ËÆæÁΩÆ????PU??ΩË??Ê®°Â??????
??????Ôº??
- `None`

Ëø????Ôº??ÆæÁΩÆÁ??CPU??ΩË??Ê®°Â??

Ëø????Á±ªÂ??Ôº??PowerMode`



> **set_threads(threads)**

ËÆæÁΩÆÂ∑•‰??Á∫øÁ????∞„??

*Ê≥®Ê??Ôº??????®Â??????OpenMP`????®°Âº??????????Ôº??????????‰ΩøÁ??????∫øÁ®????*

??????Ôº??
- `threads(int)` - Â∑•‰??Á∫øÁ????∞„??Èª??Æ§‰∏??????
Ëø????Ôº??None`

Ëø????Á±ªÂ??Ôº??void`



> **threads()**

??∑Â??ËÆæÁΩÆ????∑•‰Ω??∫øÁ®????????
??????Ôº??
- `None`

Ëø????Ôº??∑•‰Ω??∫øÁ®????

Ëø????Á±ªÂ??Ôº??int`

# PaddlePredictor

```c++
class PaddlePredictor
```

`PaddlePredictor`????addle-Lite??????Êµ????Ôº????`CreatePaddlePredictor`??πÊ??`MobileConfig`Ëø????????ª∫????????∑Â??‰ª•Ê??????addlePredictor??????????????£ËÆæÁΩÆË????•Ê????Æ„????ßË??Ê®°Â??È¢??????????????????∫‰ª•??????Âæ????????Ωø????ib????????¨‰ø°??ØÁ??????
Á§∫‰??Ôº??
```c++
int64_t ShapeProduction(const shape_t& shape) {
      int64_t res = 1;
        for (auto i : shape) res *= i;
          return res;
}

// ËÆæÁΩÆMobileConfig
MobileConfig config;
config.set_model_dir(FLAGS_model_dir);

// ??πÊ??MobileConfig????ª∫PaddlePredictor
std::shared_ptr<PaddlePredictor> predictor = CreatePaddlePredictor<MobileConfig>(config);

// ????§??????•Ê??????std::unique_ptr<Tensor> input_tensor(std::move(predictor->GetInput(0)));
input_tensor->Resize({1, 3, 224, 224});
auto* data = input_tensor->mutable_data<float>();
for (int i = 0; i < ShapeProduction(input_tensor->shape()); ++i) {
      data[i] = 1;
}

// ??ßË??È¢????
predictor->Run();

// ??∑Â??Ëæ????
std::unique_ptr<const Tensor> output_tensor(std::move(predictor->GetOutput(0)));
printf("Output dim: %d\n", output_tensor->shape()[1]);
for (int i = 0; i < ShapeProduction(output_tensor->shape()); i += 100) {
      printf("Output[%d]: %f\n", i, output_tensor->data<float>()[i]);
}
```

> **GetInput(index)**

??∑Â??Ëæ????Tensor??????Ôº??????•ËÆæÁΩÆÊ®°??????Ëæ??????∞Ê??????
??????Ôº??
- `index(int)` - Ëæ????Tensor????¥¢Âº??
Ëø????Ôº??¨¨`index`‰∏™Ëæ????`Tensor`??????????
Ëø????Á±ªÂ??Ôº??std::unique_ptr<Tensor>`



> **GetOutput(index)**

??∑Â??Ëæ????Tensor??????????????®??•Ë??????®°??????Ëæ????Áª????????
??????Ôº??
- `index(int)` - Ëæ????Tensor????¥¢Âº??
Ëø????Ôº??¨¨`index`‰∏™Ë??????ensor`????å????

Ëø????Á±ªÂ??Ôº??std::unique_ptr<Tensor>`



> **Run()**

??ßË??Ê®°Â??È¢????Ôº????Ë¶????***ËÆæÁΩÆËæ??????∞Ê??????**Ë∞????????
??????Ôº??
- `None`

Ëø????Ôº??None`

Ëø????Á±ªÂ??Ôº??void`



> **GetVersion()**

??®‰????∑Â??ÂΩ????lib‰ΩøÁ??????ª£????â??????????‰ª£Á????????Â∫??ag??????????ag‰ø°Ê??Ôº????`v2.0-beta`Ôº??????????????ª£??????`branch(commitid)`Ôº????`develop(7e44619)`????
??????Ôº??
- `None`

Ëø????Ôº????????ib‰ΩøÁ??????ª£????????¨‰ø°????
Ëø????Á±ªÂ??Ôº??std::string`

# PowerMode

```c++
enum PowerMode;
```

`PowerMode`‰∏??RM CPU??ΩË??Ê®°Â??Ôº??????∑??Ø‰ª•??πÊ??Â∫??????∫Ê??ËÆæÁΩÆ??ΩË??Ê®°Â????∑Â????????????????àÊØ????

Á§∫‰??Ôº??
```c++
MobileConfig config;
// ËÆæÁΩÆNaiveBuffer??ºÂ??Ê®°Â????ÆÂ??
config.set_model_dir(FLAGS_model_dir);
// ËÆæÁΩÆ??ΩË??Ê®°Â??
config.set_power_mode(LITE_POWER_HIGH);

// ??πÊ??MobileConfig????ª∫PaddlePredictor
std::shared_ptr<PaddlePredictor> predictor = CreatePaddlePredictor<MobileConfig>(config);
```

PowerModeËØ????ËØ¥Ê??Â¶????Ôº??
|         ????°π         | ËØ¥Ê??                                                         |
| :------------------: | ------------------------------------------------------------ |
|   LITE_POWER_HIGH    | Áª????Â§ßÊ??Ëø????Ê®°Â????????????RM CPU??ØÊ??big.LITTLEÔº????‰º??Ö??Ωø??®Âπ∂Áª????Big cluster??????????ÆæÁΩÆÁ??Á∫øÁ????∞Â§ß‰∫??§ß??∏Ê??????????????Â∞??∫øÁ®??????™Â??Áº©Ê????∞Â§ß??∏Ê????????Â¶Ç????≥ªÁª????Â≠????Â§ßÊ??????????®‰??‰∫??????∫Á??‰Ω????????????µ‰∏??????∫Á??Áª????Â§±Ë¥•Ôº????????§±Ë¥•Â??Ëø????‰∏??????∏Ê®°Âºè????|
|    LITE_POWER_LOW    | Áª????Â∞????Ëø????Ê®°Â????????????RM CPU??ØÊ??big.LITTLEÔº????‰º????‰ΩøÁ??Âπ∂Á??ÂÆ??ittle cluster??????????ÆæÁΩÆÁ??Á∫øÁ????∞Â§ß‰∫??????∏Ê??????????????Â∞??∫øÁ????∞Ë????®Áº©??æÂ??Â∞??????∞È??????????????‰∏????Â∞????Ôº????Ë????®Ë????•‰??Áª????Ê®°Â??????|
|   LITE_POWER_FULL    | Â§ßÂ????∏Ê∑∑??®Ê®°Âº????Á∫øÁ????∞Â??‰ª•Â§ß‰∫??§ß??∏Ê????????ÂΩ??∫øÁ®ã??∞Â§ß‰∫????Âø??????????Ôº????‰º??????®Â??Á∫øÁ????∞Áº©??æÂ????∏Âø?????????? |
|  LITE_POWER_NO_BIND  | ‰∏??????∏Ë??Ë°??®°Âº??º??????????????≥ªÁª??????ÆË??ËΩΩË????®Ë??Â∫??ªª??°Â??Á©∫È??????PU??∏Â??‰∏???? |
| LITE_POWER_RAND_HIGH | ËΩÆÊ??Áª????Â§ßÊ??Ê®°Â????????????ig cluster??????‰∏™Ê??Âø??????????È¢????10Ê¨°Â????á??¢Á??ÂÆ????‰∏????‰∏™Ê??Âø???? |
| LITE_POWER_RAND_LOW  | ËΩÆÊµ????ÂÆ??????∏Ê®°Âº????Â¶????Little cluster??????‰∏™Ê??Âø??????ôÊØ????Êµ??0Ê¨°Â????????Áª??????∞‰??‰∏??∏™??∏Â??????|



# Tensor

```c++
class Tensor
```

Tensor????addle-Lite????????ÆÁ??ÁªáÂΩ¢Â??Ôº????‰∫??ØπÂ∫??????∞Ê??Ëø????Â∞????Âπ∂Ê??‰æ??????£ÂØπ??∞??ÆË??Ë°????‰Ω??????????ËÆæÁΩÆShape????????Æ„??LoD‰ø°Ê??Á≠????

*Ê≥®Ê??Ôº??????∑Â??‰ΩøÁ??`PaddlePredictor`????GetInput`????GetOuput`??•Â????∑Â??Ëæ????/Ëæ????????Tensor`????

Á§∫‰??Ôº??
```c++
int64_t ShapeProduction(const shape_t& shape) {
      int64_t res = 1;
        for (auto i : shape) res *= i;
          return res;
}

// ËÆæÁΩ??obileConfig
MobileConfig config;
config.set_model_dir(FLAGS_model_dir);

// ??πÊ??MobileConfig????ª∫PaddlePredictor
std::shared_ptr<PaddlePredictor> predictor = CreatePaddlePredictor<MobileConfig>(config);

// ??????Ëæ??????∞Ê??, ??∑Â??Ëæ????Tensor
std::unique_ptr<Tensor> input_tensor(std::move(predictor->GetInput(0)));
// ËÆæÁΩÆËæ????TensorÁª¥Â∫¶‰ø°Ê??
input_tensor->Resize({1, 3, 224, 224});
// ËÆæÁΩÆËæ??????∞Ê??
auto* data = input_tensor->mutable_data<float>();
for (int i = 0; i < ShapeProduction(input_tensor->shape()); ++i) {
      data[i] = 1;
}

// ??ßË??È??Êµ??predictor->Run();

// ??∑Â??Ëæ????Tensor
std::unique_ptr<const Tensor> output_tensor(std::move(predictor->GetOutput(0)));
// ??∑Â??Ëæ????TensorÁª¥Â∫¶
printf("Output dim: %d\n", output_tensor->shape()[1]);
// ??∑Â??Ëæ????Tensor??∞Ê??
for (int i = 0; i < ShapeProduction(output_tensor->shape()); i += 100) {
      printf("Output[%d]: %f\n", i, output_tensor->data<float>()[i]);
}
```

> **Resize(shape)**

ËÆæÁΩÆTensor????ª¥Â∫??ø°??Ø„??

??Ç??∞Ô??

- `shape(std::vector<int64_t>)` - Áª¥Â∫¶‰ø°Ê??

Ëø????Ô??`None`

Ëø????Á±ªÂ??Ôº??void`



> **shape()**

??∑Â??TensorÁ??Áª¥Â∫¶‰ø°Ê??????
??????Ôº??
- `None`

Ëø????Ôº??ensor????ª¥Â∫??ø°????
Ëø????Á±ªÂ??Ôº??std::vector<int64_t>`



> **data<T>()**

```c++
template <typename T>
const T* data() const;
```

??∑Â??Tensor??????Â±??????ÆÁ??Â∏∏È????????Ôº??????Æ‰????•Á??‰∏??ê??®°????±ª????????????Â∫??????Æ„????®‰??ËØªÂ??Tensor??∞Ê??????
Á§∫‰??Ôº??
```c++
std::unique_ptr<const Tensor> output_tensor(std::move(predictor->GetOutput(0)));
// Â¶????Ê®°Â??‰∏≠Ë????∫‰∏∫floatÁ±ªÂ??
output_tensor->data<float>()
    ```

    ??????Ôº??
    - `None`

    Ëø????Ôº??Tensor`Â∫??????∞Ê??Â∏∏È????????

    Ëø????Á±ªÂ??Ôº??const T*`



    > **mutable_data<T>()**

    ```c++
    template <typename T>
    T* mutable_data() const;
    ```

    ??∑Â??Tensor??????Â±??????ÆÁö????????????πÊ??‰º??????????????®°????±ª????????????Â∫??????Æ„Ä????‰∫??ÆæÁΩ??ensor??∞Ê??????
    Á§∫‰??Ôº??
    ```c++
    std::unique_ptr<Tensor> input_tensor(std::move(predictor->GetInput(0)));
    // Â¶????Ê®°Â??‰∏≠Ë????∫‰∏∫floatÁ±ªÂ??
    auto* data = input_tensor->mutable_data<float>();
    // ËÆæÁΩÆTensor??∞Ê??
    for (int i = 0; i < ShapeProduction(input_tensor->shape()); ++i) {
          data[i] = 1;
    }
```

??????Ôº??
- `None`

Ëø????Ôº??Tensor`Â∫??????∞Ê????????

Ëø????Á±ªÂ??Ôº??T*`



> **SetLoD(lod)**

ËÆæÁΩÆTensor????oD‰ø°Ê??????
??????Ôº??
- `lod(std::vector<std::vector<uint64_t>>)` - Tensor????oD‰ø°Ê??

Ëø????Ôº??None`

Ëø????Á±ªÂ??Ôº??void`



> **lod()**

??∑Â??Tensor????oD‰ø°Ê??

??????Ôº??
- `None`

Ë????????`Tensor`????oD‰ø°Ê??

Ëø????Á±ªÂ??Ôº??std::vector<std::vector<uint64_t>>
